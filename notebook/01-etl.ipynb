{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "zip_file_path = os.path.join(os.getcwd(), \"..\", \"data\", \"raw\", \"airports-database.zip\")\n",
    "with zipfile.ZipFile(zip_file_path, \"r\") as zip_ref:\n",
    "    with zip_ref.open(\"airports-database.csv\") as csv_file:\n",
    "        df = pd.read_csv(csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "# API keys do arquivo .env\n",
    "load_dotenv()\n",
    "airportdb_key = os.getenv(\"AIRPORT_DB\")\n",
    "weatherbit_key = os.getenv(\"WEATHERBIT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "your 131072x1 screen size is bogus. expect trouble\n",
      "24/10/08 10:29:43 WARN Utils: Your hostname, ubuntu resolves to a loopback address: 127.0.1.1; using 172.24.246.235 instead (on interface eth0)\n",
      "24/10/08 10:29:43 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/10/08 10:29:45 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import requests\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import StringType, DoubleType, DateType\n",
    "from datetime import timedelta\n",
    "import time\n",
    "\n",
    "\n",
    "# Inicializando a SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"ETL\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.conf.set(\"spark.sql.legacy.timeParserPolicy\", \"LEGACY\")\n",
    "\n",
    "\n",
    "\n",
    "def get_airport_data(airport_code, api_key):\n",
    "    \"\"\"\n",
    "    Obtém informações sobre um aeroporto a partir de seu código usando a API do AirportDB.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    airport_code : str\n",
    "        Código do aeroporto (ex.: 'JFK').\n",
    "    api_key : str\n",
    "        Token da API para autenticação.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Dados do aeroporto em formato JSON.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> airport_data = get_airport_data('JFK', 'seu_api_token_aqui')\n",
    "    >>> print(airport_data)\n",
    "    {'ident': 'KJFK', 'type': 'large_airport', 'name': 'John F Kennedy International Airport', ...}\n",
    "    \"\"\"\n",
    "    url = f\"https://airportdb.io/api/v1/airport/K{airport_code}?apiToken={api_key}\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        response.raise_for_status()\n",
    "\n",
    "\n",
    "def get_weather_history(lat, lon, start_date, end_date, api_key):\n",
    "    \"\"\"\n",
    "    Obtém dados históricos de clima para uma localização específica usando a API do Weatherbit.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    lat : float\n",
    "        Latitude da localização (ex.: 40.7128).\n",
    "    lon : float\n",
    "        Longitude da localização (ex.: -74.0060).\n",
    "    start_date : str\n",
    "        Data de início no formato 'YYYY-MM-DD'.\n",
    "    end_date : str\n",
    "        Data de término no formato 'YYYY-MM-DD'.\n",
    "    api_key : str\n",
    "        Chave da API para autenticação.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Dados do clima em formato JSON.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> weather_data = get_weather_history(40.7128, -74.0060, '2023-01-01', '2023-01-02', 'seu_api_key_aqui')\n",
    "    >>> print(weather_data)\n",
    "    {'data': 'city_id': '5128581', 'city_name': 'New York City', 'country_code': 'US', ...}\n",
    "    \"\"\"\n",
    "    url = \"https://api.weatherbit.io/v2.0/history/daily\"\n",
    "    params = {\n",
    "        'lat': lat,\n",
    "        'lon': lon,\n",
    "        'start_date': start_date,\n",
    "        'end_date': end_date,\n",
    "        'key': api_key\n",
    "    }\n",
    "    headers = {\n",
    "        'Accept': 'application/json'\n",
    "    }\n",
    "    response = requests.get(url, params=params, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        response.raise_for_status()\n",
    "\n",
    "\n",
    "def enrich_airport_data(spark, df, api_token):\n",
    "    \"\"\"\n",
    "    Enriquece um DataFrame do PySpark com informações de latitude e longitude dos aeroportos.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    spark : SparkSession\n",
    "        Sessão Spark.\n",
    "    df : pyspark.sql.DataFrame\n",
    "        DataFrame contendo a coluna 'airport_cod' com os códigos dos aeroportos.\n",
    "    api_token : str\n",
    "        Token da API para autenticação.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pyspark.sql.DataFrame\n",
    "        DataFrame enriquecido com as colunas 'latitude_deg' e 'longitude_deg'.\n",
    "    \"\"\"\n",
    "    unique_codes = df.select(\"airport_cod\").distinct().rdd.flatMap(lambda x: x).collect()\n",
    "    \n",
    "    latitudes = []\n",
    "    longitudes = []\n",
    "\n",
    "    for code in unique_codes:\n",
    "        try:\n",
    "            airport_data = get_airport_data(code, api_token)\n",
    "            latitudes.append((code, airport_data.get('latitude_deg'), airport_data.get('longitude_deg')))\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Erro ao obter dados do aeroporto {code}: {e}\")\n",
    "            latitudes.append((code, None, None))\n",
    "\n",
    "    latlon_df = spark.createDataFrame(latitudes, [\"airport_cod\", \"latitude_deg\", \"longitude_deg\"])\n",
    "    return df.join(latlon_df, on=\"airport_cod\", how=\"left\")\n",
    "\n",
    "\n",
    "def get_unique_airports_by_date(df, airport_col):\n",
    "    \"\"\"\n",
    "    Obtém um DataFrame do PySpark contendo aeroportos únicos por data.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pyspark.sql.DataFrame\n",
    "        DataFrame contendo os dados de voos.\n",
    "    airport_col : str\n",
    "        Campo de origem ou destino ('origin' ou 'dest').\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pyspark.sql.DataFrame\n",
    "        DataFrame contendo aeroportos únicos e suas respectivas datas.\n",
    "    \"\"\"\n",
    "    df = df.select(airport_col, \"time_hour\")\n",
    "    df = df.withColumn(\"date\", F.to_date(\"time_hour\", \"yyyy-MM-dd\"))\n",
    "    df = df.select(F.col(airport_col).alias(\"airport_cod\"), \"date\").distinct()\n",
    "    return df\n",
    "\n",
    "\n",
    "# variável de controle para interromper o processamento\n",
    "stop_execution = [False]\n",
    "\n",
    "\n",
    "def enrich_weather_data(spark, df, api_key):\n",
    "    \"\"\"\n",
    "    Enriquece um DataFrame do PySpark com informações de velocidade do vento para as coordenadas do aeroporto.\n",
    "    Interrompe a execução ao receber o erro 429.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    spark : SparkSession\n",
    "        Sessão Spark.\n",
    "    df : pyspark.sql.DataFrame\n",
    "        DataFrame contendo colunas de data, latitude e longitude do aeroporto.\n",
    "    api_key : str\n",
    "        Chave da API para autenticação.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pyspark.sql.DataFrame\n",
    "        DataFrame enriquecido com a coluna 'wind_spd', contendo os dados obtidos até o momento.\n",
    "    \"\"\"\n",
    "\n",
    "    def fetch_weather(lat, lon, date):\n",
    "        if lat is not None and lon is not None:\n",
    "            if stop_execution[0]:\n",
    "                return None  # evita fazer requisições adicionais após erro 429\n",
    "            try:\n",
    "                start_date = date.strftime(\"%Y-%m-%d\")\n",
    "                end_date = (date + timedelta(days=1)).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "                # faz a chamada para a API de clima\n",
    "                weather_data = get_weather_history(lat, lon, start_date, end_date, api_key)\n",
    "                return weather_data[\"data\"][0][\"wind_spd\"]\n",
    "            except requests.exceptions.RequestException as e:\n",
    "                if \"429\" in str(e):\n",
    "                    print(\"Erro 429 recebido. Parando novas requisições.\")\n",
    "                    stop_execution[0] = True  # atualiza para parar futuras requisições\n",
    "                return None  # retorna None para a UDF continuar o processamento restante\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    fetch_weather_udf = F.udf(fetch_weather, DoubleType())\n",
    "\n",
    "    # enriquecendo o DataFrame com a coluna 'wind_spd'\n",
    "    df = df.withColumn(\"wind_spd\", fetch_weather_udf(F.col(\"latitude_deg\"), F.col(\"longitude_deg\"), F.col(\"date\")))\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/plbalmeida/picpay-case-machine-learning-engineer/venv/lib/python3.10/site-packages/pyspark/sql/pandas/conversion.py:485: FutureWarning: is_datetime64tz_dtype is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.DatetimeTZDtype)` instead.\n",
      "  if should_localize and is_datetime64tz_dtype(s.dtype) and s.dt.tz is not None:\n",
      "24/10/08 10:30:26 WARN TaskSetManager: Stage 0 contains a task of very large size (3929 KiB). The maximum recommended task size is 1000 KiB.\n",
      "24/10/08 10:30:29 WARN TaskSetManager: Stage 1 contains a task of very large size (3929 KiB). The maximum recommended task size is 1000 KiB.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erro ao obter dados do aeroporto PSE: 404 Client Error: Not Found for url: https://airportdb.io/api/v1/airport/KPSE?apiToken=e1974b7ce50088c4bf8c096e8722010381ebe6e8aef06041cb3cb2901699c023addbc1da0ae7ff96a58434dad6b76639\n",
      "Erro ao obter dados do aeroporto HNL: 404 Client Error: Not Found for url: https://airportdb.io/api/v1/airport/KHNL?apiToken=e1974b7ce50088c4bf8c096e8722010381ebe6e8aef06041cb3cb2901699c023addbc1da0ae7ff96a58434dad6b76639\n",
      "Erro ao obter dados do aeroporto SJU: 404 Client Error: Not Found for url: https://airportdb.io/api/v1/airport/KSJU?apiToken=e1974b7ce50088c4bf8c096e8722010381ebe6e8aef06041cb3cb2901699c023addbc1da0ae7ff96a58434dad6b76639\n",
      "Erro ao obter dados do aeroporto BQN: 404 Client Error: Not Found for url: https://airportdb.io/api/v1/airport/KBQN?apiToken=e1974b7ce50088c4bf8c096e8722010381ebe6e8aef06041cb3cb2901699c023addbc1da0ae7ff96a58434dad6b76639\n",
      "Erro ao obter dados do aeroporto ANC: 404 Client Error: Not Found for url: https://airportdb.io/api/v1/airport/KANC?apiToken=e1974b7ce50088c4bf8c096e8722010381ebe6e8aef06041cb3cb2901699c023addbc1da0ae7ff96a58434dad6b76639\n",
      "Erro ao obter dados do aeroporto STT: 404 Client Error: Not Found for url: https://airportdb.io/api/v1/airport/KSTT?apiToken=e1974b7ce50088c4bf8c096e8722010381ebe6e8aef06041cb3cb2901699c023addbc1da0ae7ff96a58434dad6b76639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/08 10:31:34 WARN TaskSetManager: Stage 9 contains a task of very large size (3929 KiB). The maximum recommended task size is 1000 KiB.\n",
      "24/10/08 10:31:35 WARN TaskSetManager: Stage 10 contains a task of very large size (3929 KiB). The maximum recommended task size is 1000 KiB.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------------+------------------+\n",
      "|airport_cod|      latitude_deg|     longitude_deg|\n",
      "+-----------+------------------+------------------+\n",
      "|        LGA|         40.777199|        -73.872597|\n",
      "|        EWR|         40.692501|        -74.168701|\n",
      "|        JFK|         40.639801|          -73.7789|\n",
      "|        PSE|              NULL|              NULL|\n",
      "|        MSY| 29.99340057373047|-90.25800323486328|\n",
      "|        SNA|         33.675701|       -117.867996|\n",
      "|        BUR|         34.197703|       -118.356378|\n",
      "|        GRR|       42.88079834|      -85.52279663|\n",
      "|        MYR|     33.6796989441|    -78.9282989502|\n",
      "|        GSO|36.097801208496094|-79.93730163574219|\n",
      "|        PVD|         41.732601|        -71.420403|\n",
      "|        OAK|         37.721298|       -122.221001|\n",
      "|        MSN|           43.1399|        -89.337502|\n",
      "|        DCA|           38.8521|        -77.037697|\n",
      "|        LEX|  38.0364990234375|-84.60590362548828|\n",
      "|        ORF| 36.89459991455078|-76.20120239257812|\n",
      "|        CRW| 38.37310028076172|-81.59320068359375|\n",
      "|        SAV|       32.12760162|      -81.20210266|\n",
      "|        CMH|         39.998001|        -82.891899|\n",
      "|        CAK|40.916099548339844|-81.44219970703125|\n",
      "+-----------+------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.createDataFrame(df)\n",
    "df = df.withColumn(\"time_hour\", F.to_timestamp(\"time_hour\", \"yyyy-MM-dd HH:mm:ss\"))\n",
    "\n",
    "# códigos de aeroportos únicos\n",
    "origin_df = df.select(\"origin\").distinct()\n",
    "dest_df = df.select(\"dest\").distinct()\n",
    "\n",
    "airports_cod_df = origin_df.union(dest_df).distinct().withColumnRenamed(\"origin\", \"airport_cod\")\n",
    "\n",
    "# enriquecendo o DataFrame com latitudes e longitudes dos aeroportos\n",
    "latlon_airport_data_df = enrich_airport_data(spark, airports_cod_df, airportdb_key)\n",
    "\n",
    "latlon_airport_data_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/08 10:31:38 WARN TaskSetManager: Stage 21 contains a task of very large size (3929 KiB). The maximum recommended task size is 1000 KiB.\n",
      "24/10/08 10:31:40 WARN TaskSetManager: Stage 22 contains a task of very large size (3929 KiB). The maximum recommended task size is 1000 KiB.\n",
      "[Stage 22:===========================================>              (6 + 2) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+\n",
      "|airport_cod|      date|\n",
      "+-----------+----------+\n",
      "|        JFK|2013-12-06|\n",
      "|        EWR|2013-12-25|\n",
      "|        EWR|2013-02-10|\n",
      "|        LGA|2013-02-17|\n",
      "|        LGA|2013-10-02|\n",
      "|        EWR|2013-04-11|\n",
      "|        LGA|2013-04-16|\n",
      "|        EWR|2013-05-25|\n",
      "|        EWR|2013-06-02|\n",
      "|        LGA|2013-08-17|\n",
      "|        EWR|2013-09-11|\n",
      "|        JFK|2013-09-29|\n",
      "|        JFK|2013-01-06|\n",
      "|        EWR|2013-01-14|\n",
      "|        LGA|2013-10-28|\n",
      "|        LGA|2013-06-16|\n",
      "|        LGA|2013-06-21|\n",
      "|        LGA|2013-07-25|\n",
      "|        LGA|2013-07-31|\n",
      "|        JFK|2013-08-03|\n",
      "+-----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# obtendo aeroportos únicos por data para origem e destino\n",
    "origin_df = get_unique_airports_by_date(df, \"origin\")\n",
    "dest_df = get_unique_airports_by_date(df, \"dest\")\n",
    "unique_airports_by_date_df = origin_df.union(dest_df).distinct()\n",
    "\n",
    "unique_airports_by_date_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/08 10:31:42 WARN TaskSetManager: Stage 30 contains a task of very large size (3929 KiB). The maximum recommended task size is 1000 KiB.\n",
      "24/10/08 10:31:43 WARN TaskSetManager: Stage 31 contains a task of very large size (3929 KiB). The maximum recommended task size is 1000 KiB.\n",
      "24/10/08 10:31:44 WARN TaskSetManager: Stage 32 contains a task of very large size (3929 KiB). The maximum recommended task size is 1000 KiB.\n",
      "24/10/08 10:31:45 WARN TaskSetManager: Stage 33 contains a task of very large size (3929 KiB). The maximum recommended task size is 1000 KiB.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+------------+-------------+\n",
      "|airport_cod|      date|latitude_deg|longitude_deg|\n",
      "+-----------+----------+------------+-------------+\n",
      "|        LGA|2013-09-04|   40.777199|   -73.872597|\n",
      "|        LGA|2013-04-10|   40.777199|   -73.872597|\n",
      "|        LGA|2013-11-08|   40.777199|   -73.872597|\n",
      "|        LGA|2013-09-15|   40.777199|   -73.872597|\n",
      "|        LGA|2013-06-03|   40.777199|   -73.872597|\n",
      "|        LGA|2013-05-28|   40.777199|   -73.872597|\n",
      "|        LGA|2013-03-04|   40.777199|   -73.872597|\n",
      "|        LGA|2013-09-08|   40.777199|   -73.872597|\n",
      "|        LGA|2013-07-26|   40.777199|   -73.872597|\n",
      "|        LGA|2013-09-17|   40.777199|   -73.872597|\n",
      "|        LGA|2013-09-11|   40.777199|   -73.872597|\n",
      "|        LGA|2013-05-17|   40.777199|   -73.872597|\n",
      "|        LGA|2013-04-03|   40.777199|   -73.872597|\n",
      "|        LGA|2013-02-23|   40.777199|   -73.872597|\n",
      "|        LGA|2013-02-13|   40.777199|   -73.872597|\n",
      "|        LGA|2013-01-11|   40.777199|   -73.872597|\n",
      "|        LGA|2013-07-13|   40.777199|   -73.872597|\n",
      "|        LGA|2013-02-28|   40.777199|   -73.872597|\n",
      "|        LGA|2013-10-24|   40.777199|   -73.872597|\n",
      "|        LGA|2013-06-24|   40.777199|   -73.872597|\n",
      "+-----------+----------+------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# unindo dados de lat/lon com aeroportos por data\n",
    "airport_data_df = unique_airports_by_date_df.join(latlon_airport_data_df, on=\"airport_cod\", how=\"inner\")\n",
    "\n",
    "airport_data_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enriquecendo o DataFrame com dados climáticos (velocidade do vento)\n",
    "final_airport_data_df = enrich_weather_data(spark, airport_data_df, weatherbit_key)\n",
    "\n",
    "# DataFrame com valores não nulos na coluna 'wind_spd'\n",
    "non_null_wind_spd_df = final_airport_data_df.filter(F.col(\"wind_spd\").isNotNull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/08 10:31:47 WARN TaskSetManager: Stage 51 contains a task of very large size (3929 KiB). The maximum recommended task size is 1000 KiB.\n",
      "24/10/08 10:31:48 WARN TaskSetManager: Stage 52 contains a task of very large size (3929 KiB). The maximum recommended task size is 1000 KiB.\n",
      "24/10/08 10:31:49 WARN TaskSetManager: Stage 53 contains a task of very large size (3929 KiB). The maximum recommended task size is 1000 KiB.\n",
      "24/10/08 10:31:49 WARN TaskSetManager: Stage 54 contains a task of very large size (3929 KiB). The maximum recommended task size is 1000 KiB.\n",
      "Erro 429 recebido. Parando novas requisições.                       (0 + 1) / 1]\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_null_wind_spd_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/08 10:31:53 WARN TaskSetManager: Stage 77 contains a task of very large size (3929 KiB). The maximum recommended task size is 1000 KiB.\n",
      "24/10/08 10:31:54 WARN TaskSetManager: Stage 78 contains a task of very large size (3929 KiB). The maximum recommended task size is 1000 KiB.\n",
      "24/10/08 10:31:55 WARN TaskSetManager: Stage 79 contains a task of very large size (3929 KiB). The maximum recommended task size is 1000 KiB.\n",
      "24/10/08 10:31:55 WARN TaskSetManager: Stage 80 contains a task of very large size (3929 KiB). The maximum recommended task size is 1000 KiB.\n",
      "Erro 429 recebido. Parando novas requisições.                       (0 + 1) / 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----+------------+-------------+--------+\n",
      "|airport_cod|date|latitude_deg|longitude_deg|wind_spd|\n",
      "+-----------+----+------------+-------------+--------+\n",
      "+-----------+----+------------+-------------+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "non_null_wind_spd_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/08 10:38:58 WARN TaskSetManager: Stage 98 contains a task of very large size (3929 KiB). The maximum recommended task size is 1000 KiB.\n",
      "[Stage 98:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+-----+---+--------+--------------+---------+--------+--------------+---------+-------+------+-------+------+----+--------+--------+----+------+-------------------+--------------------+\n",
      "| id|year|month|day|dep_time|sched_dep_time|dep_delay|arr_time|sched_arr_time|arr_delay|carrier|flight|tailnum|origin|dest|air_time|distance|hour|minute|          time_hour|                name|\n",
      "+---+----+-----+---+--------+--------------+---------+--------+--------------+---------+-------+------+-------+------+----+--------+--------+----+------+-------------------+--------------------+\n",
      "|  0|2013|    1|  1|   517.0|           515|      2.0|   830.0|           819|     11.0|     UA|  1545| N14228|   EWR| IAH|   227.0|    1400|   5|    15|2013-01-01 05:00:00|United Air Lines ...|\n",
      "|  1|2013|    1|  1|   533.0|           529|      4.0|   850.0|           830|     20.0|     UA|  1714| N24211|   LGA| IAH|   227.0|    1416|   5|    29|2013-01-01 05:00:00|United Air Lines ...|\n",
      "|  2|2013|    1|  1|   542.0|           540|      2.0|   923.0|           850|     33.0|     AA|  1141| N619AA|   JFK| MIA|   160.0|    1089|   5|    40|2013-01-01 05:00:00|American Airlines...|\n",
      "|  3|2013|    1|  1|   544.0|           545|     -1.0|  1004.0|          1022|    -18.0|     B6|   725| N804JB|   JFK| BQN|   183.0|    1576|   5|    45|2013-01-01 05:00:00|     JetBlue Airways|\n",
      "|  4|2013|    1|  1|   554.0|           600|     -6.0|   812.0|           837|    -25.0|     DL|   461| N668DN|   LGA| ATL|   116.0|     762|   6|     0|2013-01-01 06:00:00|Delta Air Lines Inc.|\n",
      "|  5|2013|    1|  1|   554.0|           558|     -4.0|   740.0|           728|     12.0|     UA|  1696| N39463|   EWR| ORD|   150.0|     719|   5|    58|2013-01-01 05:00:00|United Air Lines ...|\n",
      "|  6|2013|    1|  1|   555.0|           600|     -5.0|   913.0|           854|     19.0|     B6|   507| N516JB|   EWR| FLL|   158.0|    1065|   6|     0|2013-01-01 06:00:00|     JetBlue Airways|\n",
      "|  7|2013|    1|  1|   557.0|           600|     -3.0|   709.0|           723|    -14.0|     EV|  5708| N829AS|   LGA| IAD|    53.0|     229|   6|     0|2013-01-01 06:00:00|ExpressJet Airlin...|\n",
      "|  8|2013|    1|  1|   557.0|           600|     -3.0|   838.0|           846|     -8.0|     B6|    79| N593JB|   JFK| MCO|   140.0|     944|   6|     0|2013-01-01 06:00:00|     JetBlue Airways|\n",
      "|  9|2013|    1|  1|   558.0|           600|     -2.0|   753.0|           745|      8.0|     AA|   301| N3ALAA|   LGA| ORD|   138.0|     733|   6|     0|2013-01-01 06:00:00|American Airlines...|\n",
      "| 10|2013|    1|  1|   558.0|           600|     -2.0|   849.0|           851|     -2.0|     B6|    49| N793JB|   JFK| PBI|   149.0|    1028|   6|     0|2013-01-01 06:00:00|     JetBlue Airways|\n",
      "| 11|2013|    1|  1|   558.0|           600|     -2.0|   853.0|           856|     -3.0|     B6|    71| N657JB|   JFK| TPA|   158.0|    1005|   6|     0|2013-01-01 06:00:00|     JetBlue Airways|\n",
      "| 12|2013|    1|  1|   558.0|           600|     -2.0|   924.0|           917|      7.0|     UA|   194| N29129|   JFK| LAX|   345.0|    2475|   6|     0|2013-01-01 06:00:00|United Air Lines ...|\n",
      "| 13|2013|    1|  1|   558.0|           600|     -2.0|   923.0|           937|    -14.0|     UA|  1124| N53441|   EWR| SFO|   361.0|    2565|   6|     0|2013-01-01 06:00:00|United Air Lines ...|\n",
      "| 14|2013|    1|  1|   559.0|           600|     -1.0|   941.0|           910|     31.0|     AA|   707| N3DUAA|   LGA| DFW|   257.0|    1389|   6|     0|2013-01-01 06:00:00|American Airlines...|\n",
      "| 15|2013|    1|  1|   559.0|           559|      0.0|   702.0|           706|     -4.0|     B6|  1806| N708JB|   JFK| BOS|    44.0|     187|   5|    59|2013-01-01 05:00:00|     JetBlue Airways|\n",
      "| 16|2013|    1|  1|   559.0|           600|     -1.0|   854.0|           902|     -8.0|     UA|  1187| N76515|   EWR| LAS|   337.0|    2227|   6|     0|2013-01-01 06:00:00|United Air Lines ...|\n",
      "| 17|2013|    1|  1|   600.0|           600|      0.0|   851.0|           858|     -7.0|     B6|   371| N595JB|   LGA| FLL|   152.0|    1076|   6|     0|2013-01-01 06:00:00|     JetBlue Airways|\n",
      "| 18|2013|    1|  1|   600.0|           600|      0.0|   837.0|           825|     12.0|     MQ|  4650| N542MQ|   LGA| ATL|   134.0|     762|   6|     0|2013-01-01 06:00:00|           Envoy Air|\n",
      "| 19|2013|    1|  1|   601.0|           600|      1.0|   844.0|           850|     -6.0|     B6|   343| N644JB|   EWR| PBI|   147.0|    1023|   6|     0|2013-01-01 06:00:00|     JetBlue Airways|\n",
      "+---+----+-----+---+--------+--------------+---------+--------+--------------+---------+-------+------+-------+------+----+--------+--------+----+------+-------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
